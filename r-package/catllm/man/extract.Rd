% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract.R
\name{extract}
\alias{extract}
\title{Extract categories from text, images, or PDFs using LLMs}
\usage{
extract(
  input_data,
  api_key,
  input_type = "text",
  description = "",
  max_categories = 12L,
  categories_per_chunk = 10L,
  divisions = 12L,
  user_model = "gpt-4o",
  creativity = NULL,
  specificity = "broad",
  research_question = NULL,
  mode = "text",
  filename = NULL,
  model_source = "auto",
  iterations = 8L,
  random_state = NULL,
  focus = NULL,
  chunk_delay = 0
)
}
\arguments{
\item{input_data}{A character vector, list, or \code{data.frame} column. For
images/PDFs, a directory path or character vector of file paths.}

\item{api_key}{Character. API key for the model provider.}

\item{input_type}{Character. Type of input: \code{"text"} (default), \code{"image"},
or \code{"pdf"}.}

\item{description}{Character. The survey question or data description.
Default \code{""}.}

\item{max_categories}{Integer. Maximum number of final categories to return.
Default \code{12L}.}

\item{categories_per_chunk}{Integer. Categories to extract per data chunk.
Default \code{10L}.}

\item{divisions}{Integer. Number of chunks to divide the data into.
Default \code{12L}.}

\item{user_model}{Character. Model name. Default \code{"gpt-4o"}.}

\item{creativity}{Numeric or \code{NULL}. Temperature setting. \code{NULL} uses the
provider default. Default \code{NULL}.}

\item{specificity}{Character. Category granularity: \code{"broad"} (default) or
\code{"specific"}.}

\item{research_question}{Character or \code{NULL}. Optional research context.}

\item{mode}{Character. Processing mode. For PDFs: \code{"text"} (default),
\code{"image"}, or \code{"both"}. For images: \code{"image"} (default) or \code{"both"}.}

\item{filename}{Character or \code{NULL}. Optional CSV filename to save results.}

\item{model_source}{Character. Provider hint: \code{"auto"}, \code{"openai"},
\code{"anthropic"}, \code{"google"}, etc. Default \code{"auto"}.}

\item{iterations}{Integer. Number of passes over the data. Default \code{8L}.}

\item{random_state}{Integer or \code{NULL}. Random seed for reproducibility.}

\item{focus}{Character or \code{NULL}. Optional focus for extraction (e.g.,
\code{"decisions to move"}).}

\item{chunk_delay}{Numeric. Seconds between API calls (rate limiting).
Default \code{0.0}.}
}
\value{
A named list with:
\describe{
\item{\code{counts_df}}{A \code{data.frame} of discovered categories with counts.}
\item{\code{top_categories}}{A character vector of the top category names.}
\item{\code{raw_top_text}}{The raw model output from the final merge step.}
}
}
\description{
Wraps the Python \code{catllm.extract()} function. Discovers and returns a
normalised, deduplicated set of categories found in the input data.
}
\examples{
\dontrun{
result <- extract(
  input_data  = df$responses,
  description = "Why did you move to this city?",
  api_key     = Sys.getenv("OPENAI_API_KEY")
)
print(result$top_categories)
print(result$counts_df)
}

}
