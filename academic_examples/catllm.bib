
@article{fillenbaum_cerad_2008,
	title = {{CERAD} ({Consortium} to {Establish} a {Registry} for {Alzheimer}’s {Disease}) {The} first 20 years},
	volume = {4},
	issn = {1552-5260},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2808763/},
	doi = {10.1016/j.jalz.2007.08.005},
	abstract = {The Consortium to Establish a Registry for Alzheimer’s Disease (CERAD) was funded by the National Institute on Aging in 1986 to develop standardized, validated measures for the assessment of Alzheimer’s disease (AD). The present report describes the measures that CERAD developed during its first decade, and their continued use in their original and translated forms. These measures include clinical, neuropsychological, neuropathological and behavioral assessments of AD, and also assessment of family history and parkinsonism in AD. An approach to evaluating neuroimages did not meet the standards desired. Further evaluations which could not be completed because of lack of funding (but where some materials are available), include evaluation of very severe AD, and of service use and need by patient and caregiver. The information that was developed in the U.S. and abroad permits standardized assessment of AD in clinical practice, facilitates epidemiological studies, and provides information valuable for individual and public health planning. CERAD materials and data remain available for those wishing to use them.},
	number = {2},
	urldate = {2025-06-07},
	journal = {Alzheimer's \& dementia : the journal of the Alzheimer's Association},
	author = {Fillenbaum, Gerda G. and van Belle, Gerald and Morris, John C. and Mohs, Richard C. and Mirra, Suzanne S. and Davis, Patricia C. and Tariot, Pierre N. and Silverman, Jeremy M. and Clark, Christopher M. and Welsh-Bohmer, Kathleen A. and Heyman, Albert},
	month = mar,
	year = {2008},
	pmid = {18631955},
	pmcid = {PMC2808763},
	pages = {96--109},
	file = {Accepted Version:/Users/chrissoria/Zotero/storage/T6WT6JGD/Fillenbaum et al. - 2008 - CERAD (Consortium to Establish a Registry for Alzh.pdf:application/pdf},
}

@article{schulze_buschoff_visual_2025,
	title = {Visual cognition in multimodal large language models},
	volume = {7},
	copyright = {2025 The Author(s)},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-024-00963-y},
	doi = {10.1038/s42256-024-00963-y},
	abstract = {A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models’ limitations in the domains of causal reasoning, intuitive physics and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships and intuitive understanding of others’ preferences. Our findings reveal that, while some of these models demonstrate a notable proficiency in processing and interpreting visual data, they still fall short of human capabilities in these areas. Our results emphasize the need for integrating more robust mechanisms for understanding causality, physical dynamics and social cognition into modern-day, vision-based language models, and point out the importance of cognitively inspired benchmarks.},
	language = {en},
	number = {1},
	urldate = {2025-06-07},
	journal = {Nature Machine Intelligence},
	author = {Schulze Buschoff, Luca M. and Akata, Elif and Bethge, Matthias and Schulz, Eric},
	month = jan,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Intelligence, Learning algorithms, Object vision},
	pages = {96--106},
	file = {Full Text PDF:/Users/chrissoria/Zotero/storage/KGQRL3P9/Schulze Buschoff et al. - 2025 - Visual cognition in multimodal large language mode.pdf:application/pdf},
}

@misc{yang_large_2024,
	title = {Large {Language} {Models} for {Automated} {Open}-domain {Scientific} {Hypotheses} {Discovery}},
	url = {http://arxiv.org/abs/2309.02726},
	doi = {10.48550/arXiv.2309.02726},
	abstract = {Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are carefully manually handpicked sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses are mostly commonsense knowledge, making the task less challenging. In this work, we tackle these problems by proposing the first dataset for social science academic hypotheses discovery, with the final goal to create systems that automatically generate valid, novel, and helpful scientific hypotheses, given only a pile of raw web corpus. Unlike previous settings, the new dataset requires (1) using open-domain data (raw web corpus) as observations; and (2) proposing hypotheses even new to humanity. A multi-module framework is developed for the task, including three different feedback mechanisms to boost performance, which exhibits superior performance in terms of both GPT-4 based and expert-based evaluation. To the best of our knowledge, this is the first work showing that LLMs are able to generate novel (''not existing in literature'') and valid (''reflecting reality'') scientific hypotheses.},
	urldate = {2025-06-07},
	publisher = {arXiv},
	author = {Yang, Zonglin and Du, Xinya and Li, Junxian and Zheng, Jie and Poria, Soujanya and Cambria, Erik},
	month = jun,
	year = {2024},
	note = {arXiv:2309.02726 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: Accepted by ACL 2024 (findings)},
	file = {Preprint PDF:/Users/chrissoria/Zotero/storage/N6AR8YTY/Yang et al. - 2024 - Large Language Models for Automated Open-domain Sc.pdf:application/pdf;Snapshot:/Users/chrissoria/Zotero/storage/ANMAFX7I/2309.html:text/html},
}

@misc{sachdeva_normative_2025,
	title = {Normative {Evaluation} of {Large} {Language} {Models} with {Everyday} {Moral} {Dilemmas}},
	url = {http://arxiv.org/abs/2501.18081},
	doi = {10.48550/arXiv.2501.18081},
	abstract = {The rapid adoption of large language models (LLMs) has spurred extensive research into their encoded moral norms and decision-making processes. Much of this research relies on prompting LLMs with survey-style questions to assess how well models are aligned with certain demographic groups, moral beliefs, or political ideologies. While informative, the adherence of these approaches to relatively superficial constructs tends to oversimplify the complexity and nuance underlying everyday moral dilemmas. We argue that auditing LLMs along more detailed axes of human interaction is of paramount importance to better assess the degree to which they may impact human beliefs and actions. To this end, we evaluate LLMs on complex, everyday moral dilemmas sourced from the "Am I the Asshole" (AITA) community on Reddit, where users seek moral judgments on everyday conflicts from other community members. We prompted seven LLMs to assign blame and provide explanations for over 10,000 AITA moral dilemmas. We then compared the LLMs' judgments and explanations to those of Redditors and to each other, aiming to uncover patterns in their moral reasoning. Our results demonstrate that large language models exhibit distinct patterns of moral judgment, varying substantially from human evaluations on the AITA subreddit. LLMs demonstrate moderate to high self-consistency but low inter-model agreement. Further analysis of model explanations reveals distinct patterns in how models invoke various moral principles. These findings highlight the complexity of implementing consistent moral reasoning in artificial systems and the need for careful evaluation of how different models approach ethical judgment. As LLMs continue to be used in roles requiring ethical decision-making such as therapists and companions, careful evaluation is crucial to mitigate potential biases and limitations.},
	urldate = {2025-06-07},
	publisher = {arXiv},
	author = {Sachdeva, Pratik S. and Nuenen, Tom van},
	month = jan,
	year = {2025},
	note = {arXiv:2501.18081 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {Preprint PDF:/Users/chrissoria/Zotero/storage/WHTUHVKH/Sachdeva and Nuenen - 2025 - Normative Evaluation of Large Language Models with.pdf:application/pdf;Snapshot:/Users/chrissoria/Zotero/storage/S3VD5EF6/2501.html:text/html},
}

@article{rossi_problems_2024,
	title = {The {Problems} of {LLM}-generated {Data} in {Social} {Science} {Research}},
	volume = {18},
	copyright = {Copyright (c) 2024 Luca Rossi, Katherine Harrison, Irina Shklovski},
	issn = {1971-8853},
	url = {https://sociologica.unibo.it/article/view/19576},
	doi = {10.6092/issn.1971-8853/19576},
	abstract = {Beyond being used as fast and cheap annotators for otherwise complex classification tasks, LLMs have seen a growing adoption for generating synthetic data for social science and design research. Researchers have used LLM-generated data for data augmentation and prototyping, as well as for direct analysis where LLMs acted as proxies for real human subjects. LLM-based synthetic data build on fundamentally different epistemological assumptions than previous synthetically generated data and are justified by a different set of considerations. In this essay, we explore the various ways in which LLMs have been used to generate research data and consider the underlying epistemological (and accompanying methodological) assumptions. We challenge some of the assumptions made about LLM-generated data, and we highlight the main challenges that social sciences and humanities need to address if they want to adopt LLMs as synthetic data generators.},
	language = {en},
	number = {2},
	urldate = {2025-06-07},
	journal = {Sociologica},
	author = {Rossi, Luca and Harrison, Katherine and Shklovski, Irina},
	month = oct,
	year = {2024},
	note = {Number: 2},
	keywords = {LLM, research methods, social science, synthetic data},
	pages = {145--168},
	file = {Full Text PDF:/Users/chrissoria/Zotero/storage/S9WZ53V8/Rossi et al. - 2024 - The Problems of LLM-generated Data in Social Scien.pdf:application/pdf},
}

@misc{soria_empirical_2025,
	title = {An {Empirical} {Investigation} into the {Utility} of {Large} {Language} {Models} in {Open}-{Ended} {Survey} {Data} {Categorization}},
	url = {https://osf.io/wv6tk_v2},
	doi = {10.31235/osf.io/wv6tk_v2},
	abstract = {Can social scientists use large language models (LLMs) to code open-ended survey responses across complexity levels. This study uses the UC Berkeley Social Networks Study as a test case, comparing GPT-4o, Claude Sonnet 3.7, Llama 3.1 variant Sonnar Large, and Mistral Large against human annotators, we find the two proprietary models outperform open-source alternatives, achieving 97\% accuracy on straightforward questions and 88-91\% on complex interpretive tasks. However, open-source models still perform relatively well, achieving 95-96\% accuracy on relatively straightforward questions up to 87\% on more complex ones. Performance analysis revealed response brevity, but not category brevity, as a strong determinant of successful classification with responses under 50 characters demonstrating 7-11\% higher classification accuracy. While models effectively detected nuance in simpler tasks, they struggled with responses containing multiple reasons, narratives, and implicit meanings.

The findings imply that social science researchers who want to use LLMs should design questions to elicit concise responses (10-50 characters), implement human-in-the-loop review for complex tasks, and carefully select appropriate models based on task complexity. Minimal demographic variation in classification accuracy was observed, with Claude uniquely maintaining consistent performance across population segments. Methodologically concerning, some models sometimes produced different social narratives from open-ended classification despite high accuracy metrics.},
	language = {en-us},
	urldate = {2025-06-07},
	publisher = {OSF},
	author = {Soria, Chris},
	month = jun,
	year = {2025},
	keywords = {AI, Automated Coding, Coding, Large Language Models, Open Ended Survey Data},
	file = {OSF Preprint:/Users/chrissoria/Zotero/storage/B8WQNS5U/Soria - 2025 - An Empirical Investigation into the Utility of Lar.pdf:application/pdf},
}

@misc{jiang_survey_2024,
	title = {A {Survey} on {Large} {Language} {Models} for {Code} {Generation}},
	url = {http://arxiv.org/abs/2406.00515},
	doi = {10.48550/arXiv.2406.00515},
	abstract = {Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from the perspective of natural language processing (NLP) or software engineering (SE) or both, there is a noticeable absence of a comprehensive and up-to-date literature review dedicated to LLM for code generation. In this survey, we aim to bridge this gap by providing a systematic literature review that serves as a valuable reference for researchers investigating the cutting-edge progress in LLMs for code generation. We introduce a taxonomy to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, ethical implications, environmental impact, and real-world applications. In addition, we present a historical overview of the evolution of LLMs for code generation and offer an empirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks across various levels of difficulty and types of programming tasks to highlight the progressive enhancements in LLM capabilities for code generation. We identify critical challenges and promising opportunities regarding the gap between academia and practical development. Furthermore, we have established a dedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey) to continuously document and disseminate the most recent advances in the field.},
	urldate = {2025-06-07},
	publisher = {arXiv},
	author = {Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
	month = nov,
	year = {2024},
	note = {arXiv:2406.00515 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/chrissoria/Zotero/storage/7QTN7H6U/Jiang et al. - 2024 - A Survey on Large Language Models for Code Generat.pdf:application/pdf;Snapshot:/Users/chrissoria/Zotero/storage/4YWQBZFT/2406.html:text/html},
}

@article{llibre-guerra_caribbean-american_2021,
	title = {The {Caribbean}-{American} {Dementia} and {Aging} {Study} ({CADAS}): {A} multinational initiative to address dementia in {Caribbean} populations},
	volume = {17},
	copyright = {© 2021 the Alzheimer's Association},
	issn = {1552-5279},
	shorttitle = {The {Caribbean}-{American} {Dementia} and {Aging} {Study} ({CADAS})},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/alz.053789},
	doi = {10.1002/alz.053789},
	abstract = {Background Latinos represent the fastest growing proportion of dementia cases among different ethnic groups. Most of the studies in Alzheimer’s Disease (AD) include Latino populations within the same group, failing to sufficiently account for the real richness of linguistic, ethnic, ancestry, cultural, and socioeconomic diversity represented across Latino communities (e.g., Caribbean-Hispanic vs Non Caribbean-Hispanics), yet there is substantial AD disparities and disease heterogeneity among Hispanic groups. Methods The Caribbean-American Dementia and Aging Study (CADAS) is a multinational initiative aimed to answer key questions regarding dementia determinants and consequences in Caribbean-origin populations in origin communities as well as among emigrant populations in the United States. By building a collaborative team of leading Caribbean and U.S-based dementia researches, CADAS will analyze differences in dementia prevalence and risk factor profiles between Caribbean-Hispanics living in the main Hispanic Caribbean Islands and extend comparisons to Hispanic immigrant groups in the US as well as non-Hispanic whites, exploiting the considerable difference in life course risk exposures across these populations. Results Preliminary findings from the CADAS study indicate that prevalence of dementia in the older Caribbean population is high, both in the main islands and in U.S. compared to non-Hispanic-whites. We found overall weaker associations between education and dementia probability in the three main Caribbean islands. By contrast, a stronger association between education and dementia probability was found in the US among non-Hispanic whites, Mexican Hispanics, and non-Mexican Hispanics; these persist even after controlling for income and wealth. Conclusions There are differential associations between SES risk factors, education, and dementia probability between Caribbean islands and the U.S., which may be attributed to differences across societies in risk factors correlated with education. The CADAS study will fill a critical gap in AD knowledge, exploiting rich variation in life-course exposures to better disentangle genetic versus environmental determinants of dementia levels and disparities. Future studies within this populations will focus on early-life socioeconomic status, gene by environment interactions and societal cost.},
	language = {en},
	number = {S7},
	urldate = {2025-06-07},
	journal = {Alzheimer's \& Dementia},
	author = {Llibre-Guerra, Jorge J and Li, Jing and Harrati, Amal and Jiménez-Velazquez, Ivonne and Acosta, Daisy M and Llibre-Rodriguez, Juan J and Liu, Mao-Mei and Dow, William H},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/alz.053789},
	pages = {e053789},
	file = {Full Text PDF:/Users/chrissoria/Zotero/storage/F2HMG7WJ/Llibre-Guerra et al. - 2021 - The Caribbean-American Dementia and Aging Study (C.pdf:application/pdf;Snapshot:/Users/chrissoria/Zotero/storage/LJG4V3N6/alz.html:text/html},
}
