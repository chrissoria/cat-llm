{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test All HuggingFace App Models\n",
    "\n",
    "This notebook tests the unified text classification function with every model available in the CatLLM HuggingFace Space.\n",
    "\n",
    "Tests both:\n",
    "- **Free models** (Space pays for API costs)\n",
    "- **Paid models** (user provides own API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Add the src directory to path so we import from local code, not installed package\nsrc_path = '/Users/chrissoria/Documents/Research/cat-llm/src'\nsys.path.insert(0, src_path)\n\n# Remove any cached catllm modules to ensure we load from local\nmodules_to_remove = [key for key in sys.modules.keys() if key.startswith('catllm')]\nfor mod in modules_to_remove:\n    del sys.modules[mod]\n\nimport pandas as pd\nimport time\nfrom datetime import datetime\nfrom dotenv import load_dotenv, find_dotenv\nfrom catllm.text_functions import multi_class, detect_provider\nimport catllm\n\nprint(f\"Testing local catllm version: {catllm.__version__}\")\nprint(f\"Loaded from: {catllm.__file__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "os.chdir('/Users/chrissoria/Documents/Research/Categorization_AI_experiments')\n",
    "_ = load_dotenv(find_dotenv())\n",
    "os.chdir('/Users/chrissoria/Documents/Research/cat-llm')\n",
    "\n",
    "# Get API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "xai_api_key = os.getenv(\"XAI_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "perplexity_api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "# Verify keys loaded\n",
    "print(\"API keys loaded:\")\n",
    "print(f\"  OpenAI: {'✅' if openai_api_key else '❌'}\")\n",
    "print(f\"  Anthropic: {'✅' if anthropic_api_key else '❌'}\")\n",
    "print(f\"  Google: {'✅' if google_api_key else '❌'}\")\n",
    "print(f\"  Mistral: {'✅' if mistral_api_key else '❌'}\")\n",
    "print(f\"  xAI: {'✅' if xai_api_key else '❌'}\")\n",
    "print(f\"  HuggingFace: {'✅' if huggingface_api_key else '❌'}\")\n",
    "print(f\"  Perplexity: {'✅' if perplexity_api_key else '❌'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = os.path.join(os.getcwd(), 'examples', 'test_output')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "Models available in the HuggingFace app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free models (Space pays)\n",
    "FREE_MODEL_CHOICES = [\n",
    "    \"Qwen/Qwen3-VL-235B-A22B-Instruct:novita\",\n",
    "    \"deepseek-ai/DeepSeek-V3.1:novita\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct:groq\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gpt-4o\",\n",
    "    \"mistral-medium-2505\",\n",
    "    \"claude-3-haiku-20240307\",\n",
    "    \"grok-4-fast-non-reasoning\",\n",
    "]\n",
    "\n",
    "# Paid models (user provides key)\n",
    "PAID_MODEL_CHOICES = [\n",
    "    \"gpt-4.1\",\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"claude-sonnet-4-5-20250929\",\n",
    "    \"claude-opus-4-20250514\",\n",
    "    \"claude-3-5-haiku-20241022\",\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"mistral-large-latest\",\n",
    "]\n",
    "\n",
    "# Models routed through HuggingFace\n",
    "HF_ROUTED_MODELS = [\n",
    "    \"Qwen/Qwen3-VL-235B-A22B-Instruct:novita\",\n",
    "    \"deepseek-ai/DeepSeek-V3.1:novita\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct:groq\",\n",
    "]\n",
    "\n",
    "print(f\"Free models: {len(FREE_MODEL_CHOICES)}\")\n",
    "print(f\"Paid models: {len(PAID_MODEL_CHOICES)}\")\n",
    "print(f\"Total: {len(set(FREE_MODEL_CHOICES + PAID_MODEL_CHOICES))} unique models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test data\n",
    "TEST_RESPONSES = [\n",
    "    \"I moved because I got a new job in another city\",\n",
    "    \"My family needed to be closer to my elderly parents\",\n",
    "    \"The rent was too expensive so I had to find somewhere cheaper\",\n",
    "]\n",
    "\n",
    "TEST_CATEGORIES = [\n",
    "    \"Employment/Job-related\",\n",
    "    \"Family reasons\",\n",
    "    \"Financial/Cost of living\",\n",
    "    \"Education\",\n",
    "    \"Health reasons\",\n",
    "]\n",
    "\n",
    "print(f\"Test responses: {len(TEST_RESPONSES)}\")\n",
    "print(f\"Test categories: {len(TEST_CATEGORIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provider_for_model(model: str) -> str:\n",
    "    \"\"\"Determine the provider for a given model.\"\"\"\n",
    "    if model in HF_ROUTED_MODELS:\n",
    "        return \"huggingface\"\n",
    "\n",
    "    model_lower = model.lower()\n",
    "    if \"gpt\" in model_lower or \"o1\" in model_lower:\n",
    "        return \"openai\"\n",
    "    elif \"claude\" in model_lower:\n",
    "        return \"anthropic\"\n",
    "    elif \"gemini\" in model_lower:\n",
    "        return \"google\"\n",
    "    elif \"mistral\" in model_lower:\n",
    "        return \"mistral\"\n",
    "    elif \"grok\" in model_lower:\n",
    "        return \"xai\"\n",
    "    elif any(x in model_lower for x in [\":novita\", \":groq\", \"qwen\", \"llama\", \"deepseek\"]):\n",
    "        return \"huggingface\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def get_api_key_for_provider(provider: str) -> str:\n",
    "    \"\"\"Get API key for a provider.\"\"\"\n",
    "    key_map = {\n",
    "        \"openai\": openai_api_key,\n",
    "        \"anthropic\": anthropic_api_key,\n",
    "        \"google\": google_api_key,\n",
    "        \"mistral\": mistral_api_key,\n",
    "        \"xai\": xai_api_key,\n",
    "        \"huggingface\": huggingface_api_key,\n",
    "        \"perplexity\": perplexity_api_key,\n",
    "    }\n",
    "    return key_map.get(provider, \"\")\n",
    "\n",
    "\n",
    "def test_single_model(model: str, provider: str, api_key: str) -> dict:\n",
    "    \"\"\"Test a single model.\"\"\"\n",
    "    result = {\n",
    "        \"model\": model,\n",
    "        \"provider\": provider,\n",
    "        \"success\": False,\n",
    "        \"time\": 0,\n",
    "        \"error\": None,\n",
    "        \"results\": None,\n",
    "    }\n",
    "\n",
    "    if not api_key:\n",
    "        result[\"error\"] = f\"No API key for '{provider}'\"\n",
    "        return result\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        df = multi_class(\n",
    "            survey_input=TEST_RESPONSES[:1],  # Just 1 response for speed\n",
    "            categories=TEST_CATEGORIES,\n",
    "            api_key=api_key,\n",
    "            model=model,\n",
    "            provider=provider,\n",
    "            survey_question=\"Why did you move to your current residence?\",\n",
    "            creativity=0.1,\n",
    "            chain_of_thought=True,\n",
    "            use_json_schema=True,\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        result[\"time\"] = elapsed\n",
    "\n",
    "        if df is not None and len(df) > 0:\n",
    "            status = df['processing_status'].iloc[0]\n",
    "            if status == 'success':\n",
    "                result[\"success\"] = True\n",
    "                result[\"results\"] = df.to_dict('records')[0]\n",
    "            else:\n",
    "                result[\"error\"] = f\"Status: {status}\"\n",
    "                result[\"results\"] = df.to_dict('records')[0]\n",
    "        else:\n",
    "            result[\"error\"] = \"Empty result DataFrame\"\n",
    "\n",
    "    except Exception as e:\n",
    "        result[\"error\"] = str(e)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"Helper functions loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Free Models\n",
    "\n",
    "Testing all free models (Space pays for API costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "free_models_unique = []\n",
    "seen = set()\n",
    "for m in FREE_MODEL_CHOICES:\n",
    "    if m not in seen:\n",
    "        seen.add(m)\n",
    "        free_models_unique.append(m)\n",
    "\n",
    "print(f\"Testing {len(free_models_unique)} free models...\\n\")\n",
    "\n",
    "free_results = []\n",
    "\n",
    "for i, model in enumerate(free_models_unique, 1):\n",
    "    provider = get_provider_for_model(model)\n",
    "    api_key = get_api_key_for_provider(provider)\n",
    "\n",
    "    print(f\"[{i}/{len(free_models_unique)}] Testing {model} ({provider})...\")\n",
    "\n",
    "    result = test_single_model(model, provider, api_key)\n",
    "    free_results.append(result)\n",
    "\n",
    "    status_icon = \"✅\" if result[\"success\"] else \"❌\"\n",
    "    if result[\"success\"]:\n",
    "        print(f\"  {status_icon} PASS ({result['time']:.2f}s)\")\n",
    "    else:\n",
    "        print(f\"  {status_icon} FAIL: {result['error']}\")\n",
    "\n",
    "    if i < len(free_models_unique):\n",
    "        time.sleep(1)  # Rate limiting\n",
    "\n",
    "# Summary\n",
    "passed = sum(1 for r in free_results if r[\"success\"])\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FREE MODELS SUMMARY: {passed}/{len(free_results)} passed\")\n",
    "print(f\"{'='*70}\")\n",
    "for r in free_results:\n",
    "    icon = \"✅\" if r[\"success\"] else \"❌\"\n",
    "    time_str = f\"({r['time']:.2f}s)\" if r[\"success\"] else r[\"error\"]\n",
    "    print(f\"  {icon} {r['model']}: {time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Paid Models\n",
    "\n",
    "Testing all paid models (user provides API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "paid_models_unique = []\n",
    "seen = set()\n",
    "for m in PAID_MODEL_CHOICES:\n",
    "    if m not in seen:\n",
    "        seen.add(m)\n",
    "        paid_models_unique.append(m)\n",
    "\n",
    "print(f\"Testing {len(paid_models_unique)} paid models...\\n\")\n",
    "\n",
    "paid_results = []\n",
    "\n",
    "for i, model in enumerate(paid_models_unique, 1):\n",
    "    provider = get_provider_for_model(model)\n",
    "    api_key = get_api_key_for_provider(provider)\n",
    "\n",
    "    print(f\"[{i}/{len(paid_models_unique)}] Testing {model} ({provider})...\")\n",
    "\n",
    "    result = test_single_model(model, provider, api_key)\n",
    "    paid_results.append(result)\n",
    "\n",
    "    status_icon = \"✅\" if result[\"success\"] else \"❌\"\n",
    "    if result[\"success\"]:\n",
    "        print(f\"  {status_icon} PASS ({result['time']:.2f}s)\")\n",
    "    else:\n",
    "        print(f\"  {status_icon} FAIL: {result['error']}\")\n",
    "\n",
    "    if i < len(paid_models_unique):\n",
    "        time.sleep(1)  # Rate limiting\n",
    "\n",
    "# Summary\n",
    "passed = sum(1 for r in paid_results if r[\"success\"])\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PAID MODELS SUMMARY: {passed}/{len(paid_results)} passed\")\n",
    "print(f\"{'='*70}\")\n",
    "for r in paid_results:\n",
    "    icon = \"✅\" if r[\"success\"] else \"❌\"\n",
    "    time_str = f\"({r['time']:.2f}s)\" if r[\"success\"] else r[\"error\"]\n",
    "    print(f\"  {icon} {r['model']}: {time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Combine all results\n",
    "all_results = free_results + paid_results\n",
    "\n",
    "# Create DataFrame\n",
    "rows = []\n",
    "for r in all_results:\n",
    "    row = {\n",
    "        \"model\": r[\"model\"],\n",
    "        \"provider\": r[\"provider\"],\n",
    "        \"success\": r[\"success\"],\n",
    "        \"time_seconds\": r[\"time\"],\n",
    "        \"error\": r[\"error\"],\n",
    "    }\n",
    "    if r[\"results\"]:\n",
    "        for i, cat in enumerate(TEST_CATEGORIES, 1):\n",
    "            row[f\"category_{i}\"] = r[\"results\"].get(f\"category_{i}\", None)\n",
    "    rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save CSV\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_path = os.path.join(output_dir, f\"model_test_results_{timestamp}.csv\")\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"Results saved to: {csv_path}\")\n",
    "\n",
    "# Save detailed JSON\n",
    "json_path = os.path.join(output_dir, f\"model_test_results_{timestamp}.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump({\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"catllm_version\": catllm.__version__,\n",
    "        \"test_responses\": TEST_RESPONSES,\n",
    "        \"test_categories\": TEST_CATEGORIES,\n",
    "        \"results\": all_results,\n",
    "    }, f, indent=2, default=str)\n",
    "print(f\"Detailed results: {json_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "total_passed = sum(1 for r in all_results if r[\"success\"])\n",
    "print(f\"Total: {len(all_results)}\")\n",
    "print(f\"Passed: {total_passed} ✅\")\n",
    "print(f\"Failed: {len(all_results) - total_passed} ❌\")\n",
    "\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}